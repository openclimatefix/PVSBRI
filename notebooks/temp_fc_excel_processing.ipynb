{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb66640",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "import pytz\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b73ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to parse excel files and return a dataframe\n",
    "def parse_excel(file_path):\n",
    "    wb = load_workbook(file_path, read_only=True,data_only=True)\n",
    "    ws = wb.active\n",
    "\n",
    "    # Get the date from cell A1\n",
    "    date = pd.to_datetime(ws['A1'].value, format='%Y%m%d')\n",
    "\n",
    "    # Create an empty DataFrame\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # Extract the data from the specified cells\n",
    "    for row in range(6, 30):\n",
    "        hour = ws['A' + str(row)].value\n",
    "        datetime_index = pd.to_datetime(date + pd.DateOffset(hours=hour))\n",
    "        \n",
    "        demand_data = ws['B' + str(row)].value\n",
    "        pv_data = ws['E' + str(row)].value\n",
    "        mgp_sicily_forecast = ws['H' + str(row)].value\n",
    "        mgp_sicily_realised = ws['I' + str(row)].value\n",
    "        mgp_sicily_error = ws['J' + str(row)].value\n",
    "\n",
    "        data = {'demand_data': [demand_data], \n",
    "                'pv_data': [pv_data], \n",
    "                'mgp_sicily_forecast': [mgp_sicily_forecast], \n",
    "                'mgp_sicily_realised': [mgp_sicily_realised],\n",
    "                'mgp_sicily_error': [mgp_sicily_error]}\n",
    "\n",
    "        df_temp = pd.DataFrame(data, index=[datetime_index])\n",
    "        df = pd.concat([df, df_temp])\n",
    "\n",
    "    return df\n",
    "\n",
    "# Define the path of the directory\n",
    "dir_path = \"ADD PATH\"\n",
    "  # Add your directory path here\n",
    "\n",
    "# Create an empty DataFrame\n",
    "df_total = pd.DataFrame()\n",
    "\n",
    "# Loop through each file in the directory\n",
    "for file in os.listdir(dir_path):\n",
    "    if file.endswith('.xlsx') or file.endswith('.xls'):\n",
    "        file_path = os.path.join(dir_path, file)\n",
    "        df = parse_excel(file_path)\n",
    "        df_total = pd.concat([df_total, df])\n",
    "        \n",
    "df_total.sort_index(inplace=True)\n",
    "        \n",
    "# Reset index\n",
    "df_total.reset_index(inplace=True)\n",
    "\n",
    "df_total = df_total.rename(columns={'index': 'datetime'})\n",
    "\n",
    "# df_total = df_total.sort_values('index')\n",
    "\n",
    "# Print the dataframe\n",
    "print(df_total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fb9173",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.to_csv(\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484ea3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loaded = pd.read_csv(\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97594f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2960fa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Apply UTC Convention\n",
    "# View all timezones using the code below\n",
    "\"\"\"\n",
    ">>> import pytz\n",
    ">>> pytz.all_timezones\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def convert_to_utc(df, source_timezone):\n",
    "    # Ensure the DataFrame has a DatetimeIndex\n",
    "    #     if not isinstance(df.index, pd.DatetimeIndex):\n",
    "    #         raise ValueError(\"The DataFrame must have a DatetimeIndex.\")\n",
    "\n",
    "    # Create timezone objects for source and target (UTC) timezones\n",
    "    source_tz = pytz.timezone(source_timezone)\n",
    "    target_tz = pytz.UTC\n",
    "\n",
    "    # Convert the \"datetime\" column to a DatetimeIndex\n",
    "    # df['Datetime'] = pd.to_datetime(df['Datetime'])\n",
    "\n",
    "    if not isinstance(df, pd.DatetimeIndex):\n",
    "        # Convert the \"datetime\" column to a DatetimeIndex\n",
    "        df[\"datetime\"] = pd.to_datetime(df[\"datetime\"])\n",
    "        df.set_index(\"datetime\", inplace=True)\n",
    "\n",
    "    # df.set_index('Datetime', inplace=True)\n",
    "\n",
    "    # Localize the DatetimeIndex to the source timezone, handling ambiguous and non-existent times\n",
    "    df_source_tz = df.index.tz_localize(source_tz, ambiguous=\"NaT\", nonexistent=\"NaT\")\n",
    "\n",
    "    # Convert the DatetimeIndex to the target timezone (UTC)\n",
    "    df_utc = df_source_tz.tz_convert(target_tz)\n",
    "\n",
    "    # Set the DatetimeIndex as a column in the DataFrame\n",
    "    df[\"ts\"] = df_utc\n",
    "\n",
    "    df.set_index(\"ts\", inplace=True)\n",
    "\n",
    "    # to get rid of the time zone different impliment:\n",
    "    # Format the DatetimeIndex without the timezone offset\n",
    "    # df_utc.index = df_utc.index.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# orginally got this error: NonExistentTimeError: 2019-03-31 02:00:00, so they dont adjust for daylight savings.\n",
    "\n",
    "\n",
    "source_timezone = \"Europe/Malta\"  # Replace with the desired timezone\n",
    "df_UTC = convert_to_utc(df_loaded, source_timezone)\n",
    "\n",
    "\n",
    "# will need to createa a lamda/function to go through all of the 15min data to convert it\n",
    "# to the correct UTC. It would be worth making this into a function so it can be used by the hourly.\n",
    "# Want it so that i just have to pass a dataframe that has a Datetime funciton into it.\n",
    "\n",
    "print(\"-------- COMPLETE 3 -------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe38613",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_UTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43273565",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_UTC.to_csv(\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264a4228",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_UTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7284c948",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_UTC.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c22750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_UTC['ts'] = pd.to_datetime(df_UTC['ts'])\n",
    "df_UTC['ts'] = df_UTC['ts'].astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91699c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_UTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a446b7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_UTC = df_UTC.set_index('ts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e8ff00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_UTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b118153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdtocdf(df):\n",
    "    \n",
    "    \n",
    "#     df_UTC.index = pd.to_datetime(df_UTC.index)\n",
    "#     df.reset_index(drop=False)\n",
    "    \n",
    "    data_array = xr.Dataset(df)\n",
    "    \n",
    "    data_array = data_array.rename({'pv_data': 'power'})\n",
    "    \n",
    "    data_array = data_array.expand_dims({\"pv_id\": [0]})\n",
    "    \n",
    "    data_array = data_array.assign_coords({\"latitude\": [35]})\n",
    "    data_array = data_array.assign_coords({\"longitude\": [15]})\n",
    "\n",
    "#     data_array = data_array.set_coords(\"ts\").swap_dims({\"dim_0\": \"ts\"})\n",
    "\n",
    "#     data_array = data_array.drop(\"dim_0\")\n",
    "\n",
    "\n",
    "    # Save the DataArray as a NetCDF file\n",
    "    data_array.to_netcdf(\"...\")\n",
    "\n",
    "\n",
    "    return data_array\n",
    "\n",
    "\n",
    "data_array = pdtocdf(df_UTC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c497f453",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194181cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
