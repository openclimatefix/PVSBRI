{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- Import Libs ---------\n",
    "\n",
    "from datetime import datetime\n",
    "import os \n",
    "import pathlib\n",
    "\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "import warnings\n",
    "import re\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "alt.renderers.enable('altair_viewer')\n",
    "\n",
    "#Disbale the max row limit for altair datasets.\n",
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It's always annoying to set the working directory: we use an environment variable defined in the Makefile.\n",
    "CWD = os.environ.get(\"CWD\")\n",
    "if CWD:\n",
    "    os.chdir(CWD)\n",
    "    \n",
    "print(CWD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop through each file in the folder, add each pandas dataframe to an array\n",
    "#This could be useful for checking any null values etc later on.\n",
    "def convert_to_df(folder_path):\n",
    "    \n",
    "    df_list =[]\n",
    "    \n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".xlsx\"):  # Check if the file is an Excel file\n",
    "            # Load the Excel file into a dataframe using pandas\n",
    "            df = pd.read_excel(os.path.join(folder_path, filename),engine='openpyxl')\n",
    "            # Append the dataframe to the list\n",
    "            df_list.append(df)\n",
    "    \n",
    "    return df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop through each folder and store the excel files all together in one long list of arrays\n",
    "def load_data_from_excel_files(folder_path):\n",
    "    # Get a list of all Excel files in the folder\n",
    "    excel_files = [f for f in os.listdir(folder_path) if f.endswith('.xlsx') or f.endswith('.xls')]\n",
    "\n",
    "    # Initialize an empty DataFrame\n",
    "    combined_data = pd.DataFrame()\n",
    "    \n",
    "        # Suppress the openpyxl UserWarning\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "        warnings.filterwarnings(\"ignore\", message=\"Workbook contains no default style, apply openpyxl's default\", category=UserWarning)\n",
    "\n",
    "\n",
    "    # Iterate through the Excel files, read their data, and concatenate them into the combined_data DataFrame\n",
    "    for excel_file in excel_files:\n",
    "        file_path = os.path.join(folder_path, excel_file)\n",
    "        df = pd.read_excel(file_path, engine='openpyxl')\n",
    "        combined_data = pd.concat([combined_data, df], ignore_index=True)\n",
    "\n",
    "    return combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = './data/island_A/15-min-PV/2019/'\n",
    "combined_data_solo = load_data_from_excel_files(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined_data_solo)\n",
    "print(combined_data_solo.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = './data/island_A/15-min-PV/2019/'\n",
    "combined_data_multiple = convert_to_df(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined_data_multiple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets first just load a single excel file from the 15min data and have a look at it\n",
    "def read_excel_file(file_path):\n",
    "    df = pd.read_excel(file_path, engine='openpyxl')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XXXXXXX represents the last bit of the file name\n",
    "\n",
    "#file_path = \"./data/island_A/15-min-PV/2019/2019-01-01_XXXXXXX.xlsx\"\n",
    "single_data = read_excel_file(file_path)\n",
    "\n",
    "# # Convert the 'time' column to datetime.time objects\n",
    "single_data['Time'] = pd.to_datetime(single_data['Time'], format='%H:%M:%S').dt.time\n",
    "single_data['Time'] = single_data['Time'].astype(str)\n",
    "\n",
    "# Convert the 'time' column to datetime objects with a reference date\n",
    "reference_date = '2000-01-01'\n",
    "single_data['Time'] = pd.to_datetime(reference_date + ' ' + single_data['Time'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "\n",
    "# Convert the 'time' column to string format\n",
    "#single_data['Time'] = single_data['Time'].astype(str)\n",
    "\n",
    "print(single_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Altair time series chart\n",
    "alt.Chart(single_data).mark_line().encode(\n",
    "    x=alt.X('Time:T', title='Time'), # 'time' is the column name for the x-axis, and 'T' denotes it's a temporal (time-based) field\n",
    "    y=alt.X('15-Minute Output MWh:Q', title='15-Minute Output MWh') # '15-Minute Output MWh' is the column name for the y-axis, and 'Q' denotes it's a quantitative (numerical) field\n",
    ").properties(\n",
    "    title='Single Day'\n",
    ")\n",
    "\n",
    "# # Display the chart\n",
    "# chart.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Altair to work need to extract the information stored in the file name for each file about the data\n",
    "#This then needs to be set as the refernece date and the Time collumns updated accordingly\n",
    "\n",
    "#XXXXXX represents the last bit of the file name \n",
    "\n",
    "filename = \"2019-01-01_XXXXXX.xlsx\"\n",
    "\n",
    "# Split the filename by '_'\n",
    "parts = filename.split(\"_\")\n",
    "\n",
    "# Extract date and location information\n",
    "date_str = parts[0]\n",
    "location = parts[1].split(\".\")[0]  # Remove the file extension\n",
    "\n",
    "print(\"Date:\", date_str)\n",
    "print(\"Location:\", location)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trying to do it for a lot of charts now\n",
    "#I should also make the folder path a variable so that I am perform some quick stats analysis on it\n",
    "def folder_data_load(folder_path):\n",
    "    #This is a list of all of the filenames\n",
    "    files = os.listdir(folder_path)\n",
    "\n",
    "    # Read all Excel files into a list of dataframes\n",
    "    dataframes = []\n",
    "\n",
    "    for filename in files:\n",
    "        if filename.endswith('.xlsx'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "            # Extract the reference date from the filename\n",
    "            reference_date = filename.split('_')[0]\n",
    "\n",
    "            df = pd.read_excel(file_path, engine='openpyxl')\n",
    "            \n",
    "            #create new columns in the data for date specific\n",
    "            df[\"Year\"] = reference_date.split('-')[0]\n",
    "            df[\"Month\"] = reference_date.split('-')[1]\n",
    "            df[\"Day\"] = reference_date.split('-')[2]\n",
    "\n",
    "            # Convert the 'Time' column to datetime.time objects\n",
    "            df['Time'] = pd.to_datetime(df['Time'], format='%H:%M:%S').dt.time\n",
    "            df['Time'] = df['Time'].astype(str)\n",
    "\n",
    "            # Convert the 'Time' column to datetime objects using the extracted reference date\n",
    "            df['Time'] = pd.to_datetime(reference_date + ' ' + df['Time'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "            dataframes.append(df)\n",
    "        \n",
    "    return dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = './data/island_A/15-min-PV/2019/'\n",
    "dataframes = folder_data_load(folder_path)\n",
    "print(dataframes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dataframes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create individual charts for each DataFrame and put them all together\n",
    "charts = [\n",
    "    alt.Chart(df).mark_line().encode(\n",
    "        x=alt.X('Time:T', title='Time'),\n",
    "        y=alt.Y('15-Minute Output MWh:Q', title='15-Minute Output MWh')\n",
    "    ).properties(width=300, height=200)\n",
    "    for df in dataframes\n",
    "]\n",
    "\n",
    "# Combine the charts into a grid layout\n",
    "num_columns = 5\n",
    "combined_chart = alt.vconcat(*[alt.hconcat(*charts[i:i+num_columns]) for i in range(0, len(charts), num_columns)])\n",
    "\n",
    "# Display the chart\n",
    "combined_chart.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = './data/island_A/15-min-PV/2019/'\n",
    "dataframes = folder_data_load(folder_path)\n",
    "print(dataframes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same as above but with a set scale\n",
    "# Create individual charts for each DataFrame and put them all together\n",
    "charts = [\n",
    "    alt.Chart(df).mark_line().encode(\n",
    "        x=alt.X('Time:T', title=''),\n",
    "        y=alt.Y('15-Minute Output MWh:Q', title='',  scale=alt.Scale(domain=(0, 30),clamp=True))\n",
    "    ).properties(width=300, height=200)\n",
    "    for df in dataframes\n",
    "]\n",
    "\n",
    "# Combine the charts into a grid layout\n",
    "num_columns = 10\n",
    "combined_chart = alt.vconcat(*[alt.hconcat(*charts[i:i+num_columns]) for i in range(0, len(charts), num_columns)])\n",
    "\n",
    "# Display the chart\n",
    "combined_chart.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function does the same as above but orders the dataframe correctly \n",
    "\n",
    "#I should also make the folder path a variable so that I am perform some quick stats analysis on it\n",
    "def folder_data_load_sorted(folder_path):\n",
    "    #This is a list of all of the filenames\n",
    "    files = os.listdir(folder_path)\n",
    "\n",
    "    # Read all Excel files into a list of dataframes\n",
    "    dataframes = []\n",
    "\n",
    "    for filename in files:\n",
    "        if filename.endswith('.xlsx'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "            # Extract the reference date from the filename\n",
    "            reference_date = filename.split('_')[0]\n",
    "\n",
    "            df = pd.read_excel(file_path, engine='openpyxl')\n",
    "            \n",
    "            #create new columns in the data for date specific\n",
    "            df[\"Year\"] = reference_date.split('-')[0]\n",
    "            df[\"Month\"] = reference_date.split('-')[1]\n",
    "            df[\"Day\"] = reference_date.split('-')[2]\n",
    "\n",
    "            # Convert the 'Time' column to datetime.time objects\n",
    "            df['Time'] = pd.to_datetime(df['Time'], format='%H:%M:%S').dt.time\n",
    "            df['Time'] = df['Time'].astype(str)\n",
    "\n",
    "            # Convert the 'Time' column to datetime objects using the extracted reference date\n",
    "            df['Time'] = pd.to_datetime(reference_date + ' ' + df['Time'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "            #This returns a tuple\n",
    "            dataframes.append((reference_date, df))\n",
    "    \n",
    "    dataframes.sort(key=lambda x: x[0])\n",
    "    \n",
    "    sorted_dataframes = [df for _,df in dataframes]\n",
    "        \n",
    "    return sorted_dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = './data/island_A/15-min-PV/2019/'\n",
    "dataframes_sorted = folder_data_load_sorted(folder_path)\n",
    "print(dataframes_sorted[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charts = [\n",
    "    alt.Chart(df).mark_line().encode(\n",
    "        x=alt.X('Time:T', title=''),\n",
    "        y=alt.Y('15-Minute Output MWh:Q', title='',  scale=alt.Scale(domain=(0, 30),clamp=True))\n",
    "    ).properties(width=300, height=200)\n",
    "    for df in dataframes_sorted\n",
    "]\n",
    "\n",
    "# Combine the charts into a grid layout\n",
    "num_columns = 20\n",
    "combined_chart = alt.vconcat(*[alt.hconcat(*charts[i:i+num_columns]) for i in range(0, len(charts), num_columns)])\n",
    "\n",
    "# Display the chart\n",
    "combined_chart.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to check if any negative values\n",
    "#Need to find max value\n",
    "#Need to find varinace in max value (mean/medium max value) in each day\n",
    "#Compare dates\n",
    "#Check the issue occuring due to Sundays displaying the month"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
